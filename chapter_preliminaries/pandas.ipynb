{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "centered-massachusetts",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "## Reading the Dataset\n",
    "\n",
    "As an example, we begin by creating an artificial dataset that is stored in a\n",
    "csv (comma-separated values) file `../data/house_tiny.csv`. Data stored in other\n",
    "formats may be processed in similar ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dominant-approval",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-19T20:04:04.089278Z",
     "iopub.status.busy": "2021-01-19T20:04:04.084471Z",
     "iopub.status.idle": "2021-01-19T20:04:04.093003Z",
     "shell.execute_reply": "2021-01-19T20:04:04.092363Z"
    },
    "origin_pos": 1,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('NumRooms,Alley,Price\\n')  # Column names\n",
    "    f.write('NA,Pave,127500\\n')  # Each row represents a data example\n",
    "    f.write('2,NA,106000\\n')\n",
    "    f.write('4,NA,178100\\n')\n",
    "    f.write('NA,NA,140000\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-anime",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "To load the raw dataset from the created csv file,\n",
    "we import the `pandas` package and invoke the `read_csv` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "parental-cricket",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-19T20:04:04.096555Z",
     "iopub.status.busy": "2021-01-19T20:04:04.096006Z",
     "iopub.status.idle": "2021-01-19T20:04:04.421432Z",
     "shell.execute_reply": "2021-01-19T20:04:04.420849Z"
    },
    "origin_pos": 3,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley   Price\n",
      "0       NaN  Pave  127500\n",
      "1       2.0   NaN  106000\n",
      "2       4.0   NaN  178100\n",
      "3       NaN   NaN  140000\n"
     ]
    }
   ],
   "source": [
    "# If pandas is not installed, just uncomment the following line:\n",
    "# !pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-attitude",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "Note that \"NaN\" entries are missing values.\n",
    "\n",
    "To handle missing data, typical methods include *imputation* and *deletion*,\n",
    "where imputation replaces missing values with substituted ones,\n",
    "while deletion ignores missing values. Here we will consider imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "solar-emperor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-19T20:04:04.429180Z",
     "iopub.status.busy": "2021-01-19T20:04:04.428637Z",
     "iopub.status.idle": "2021-01-19T20:04:04.431935Z",
     "shell.execute_reply": "2021-01-19T20:04:04.431369Z"
    },
    "origin_pos": 5,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley\n",
      "0       3.0  Pave\n",
      "1       2.0   NaN\n",
      "2       4.0   NaN\n",
      "3       3.0   NaN\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prime-raleigh",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-19T20:04:04.441137Z",
     "iopub.status.busy": "2021-01-19T20:04:04.440589Z",
     "iopub.status.idle": "2021-01-19T20:04:04.443668Z",
     "shell.execute_reply": "2021-01-19T20:04:04.443191Z"
    },
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  Alley_Pave  Alley_nan\n",
      "0       3.0           1          0\n",
      "1       2.0           0          1\n",
      "2       4.0           0          1\n",
      "3       3.0           0          1\n"
     ]
    }
   ],
   "source": [
    "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gross-system",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-19T20:04:04.447248Z",
     "iopub.status.busy": "2021-01-19T20:04:04.446639Z",
     "iopub.status.idle": "2021-01-19T20:04:04.827761Z",
     "shell.execute_reply": "2021-01-19T20:04:04.827054Z"
    },
    "origin_pos": 9,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 1., 0.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 0., 1.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500, 106000, 178100, 140000]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\n",
    "X, y"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "language_info": {
   "name": "python"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}